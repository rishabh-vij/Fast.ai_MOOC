{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/rishabh-vij/Fast.ai_MOOC/blob/master/Week%206/ANN%20and%20RNN%20from%20scratch.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "EjL_H7W_I878",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Language model(ANN and RNN) from scracth"
      ]
    },
    {
      "metadata": {
        "id": "pn-kWaUm_hNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install opencv-python\n",
        "#!apt update && apt install -y libsm6 libxext6\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "! pip3 install fastai\n",
        "#!pip3 install torchvision\n",
        "#! pip install torchtext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j2pQzPDuBGC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gCMi4pmCNse",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**We're going to download the collected works of Nietzsche to use as our data for this class.**"
      ]
    },
    {
      "metadata": {
        "id": "Yxi88hPKB95-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH='data/nietzsche/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KT6tjaCrCd2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c7f6749-cc07-423f-f3f5-d8ee6183d02f"
      },
      "cell_type": "code",
      "source": [
        "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt: 606kB [00:01, 417kB/s]                           "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yAWvKBI8Cg7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99f07cf4-4bb3-470c-8322-56f7b9395449"
      },
      "cell_type": "code",
      "source": [
        "text[:500]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself to be won; and\\nat present every kind of dogma stands with sad and discouraged mien--IF,\\nindeed, it s'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "NzkSwhWpClQ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars=sorted(list(set(text)))\n",
        "vocab_size=len(chars)+1\n",
        "chars.insert(0,'\\0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQDmsgDRCm8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29167082-1e1c-4ca6-a827-21ddf89ed814"
      },
      "cell_type": "code",
      "source": [
        "' '.join(chars)[:-50]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\x00 \\n   ! \" \\' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; = ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] _ a b c d e f'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "9f6SlkoCE2Qz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Map chars to indices and vice-versa**"
      ]
    },
    {
      "metadata": {
        "id": "QBT1Q8_VDS1U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices={c:i for i,c in enumerate(chars)}\n",
        "indices_char={i:c for i,c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zgfNZ66IH4ZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**idx will be the data we use from now on - it simply converts all the characters to their index (based on the mapping above)**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4qbq0Z9lFTCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b5a115a-af7f-4992-fbd1-8d308b774dbb"
      },
      "cell_type": "code",
      "source": [
        "idx=[char_indices[i] for i in text]\n",
        "idx[:6]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 42, 29, 30, 25, 27]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "j5bo7Z1RIpoi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##3 character model\n",
        "\n",
        "**We'll now try building a model from scratch using pytorch that given the first 3 characters predicts the 4th one**"
      ]
    },
    {
      "metadata": {
        "id": "W4ItROjxFVBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=3 #organizing our data \n",
        "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
        "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
        "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
        "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7WV0x9qzJ2ZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.stack(c1_dat)\n",
        "x2 = np.stack(c2_dat)\n",
        "x3 = np.stack(c3_dat)\n",
        "#^ Inputs\n",
        "y=np.stack(c4_dat)\n",
        "#^ Output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8L2tgi33Kgau",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03b195a5-ccc5-4c51-b69e-12f2be6ea2db"
      },
      "cell_type": "code",
      "source": [
        "# first 4 inputs\n",
        "x1[:4], x2[:4], x3[:4]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "0uGzucB9KiTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "760d505e-4275-49e3-bade-a63eb98235ff"
      },
      "cell_type": "code",
      "source": [
        "# first 4 outputs\n",
        "y[:4]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 29,  1, 40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fCChR4EoLneE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating and training model\n"
      ]
    },
    {
      "metadata": {
        "id": "MBsAQhgMLUKE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden=256 # no. of hidden layers in our model\n",
        "n_fac=42 # Size of the embedding matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TvrB7wZmL6E1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class char3model(nn.Module):\n",
        "  def __init__(self,vocab_size,n_fac):\n",
        "    super().__init__()\n",
        "    self.e=nn.Embedding(vocab_size,n_fac) # create embedding matrix\n",
        "    \n",
        "    self.l_lin = nn.Linear(n_fac,n_hidden) # layer that connects inputs layer and hidden layer\n",
        "    self.l_hidden = nn.Linear(n_hidden,n_hidden) # layer that connects 2 hidden layers\n",
        "    self.l_out = nn.Linear(n_hidden,vocab_size) # layer that connects hidden layer to output layer\n",
        "    \n",
        "  def forward(self,c1,c2,c3):\n",
        "    in1= F.relu(self.l_lin(self.e(c1)))#passing each character input through embedding layer, linear layer and applying RELU\n",
        "    in2= F.relu(self.l_lin(self.e(c2)))\n",
        "    in3= F.relu(self.l_lin(self.e(c3)))\n",
        "    \n",
        "    h=V(torch.zeros(in1.size()).cuda()) #creating the hidden layer and putting it on GPU\n",
        "    h= F.tanh(self.l_hidden(h+in1))\n",
        "    h= F.tanh(self.l_hidden(h+in2))\n",
        "    h= F.tanh(self.l_hidden(h+in3))\n",
        "    return F.log_softmax(self.l_out(h))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9Lno7lKR47z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md= ColumnarModelData.from_arrays('.',[-1],np.stack([x1,x2,x3], axis=1), y, bs=512) # We use fastai's ColumnarModelData to pass our data i.e. x1,x2,x3 to our forward method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLrhU4wbSWO8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=char3model(vocab_size,n_fac).cuda() #creating a model from just created class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uj1iDk-FTbc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "*xs,yt=next(iter(md.trn_dl))\n",
        "t = model(*V(xs))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iNdURPz1UhXz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt=optim.Adam(model.parameters(),1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-pEGjOCVaKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c342c0f4-dc1b-426a-8679-6a9718d13954"
      },
      "cell_type": "code",
      "source": [
        "fit(model,md,1,opt,F.nll_loss)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de108f22d28340fb867b597aa1cad90d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.105959   1.10178   \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.10178])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "nTAzdxckVs83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt,1e-3) #Learning rate annealing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_2IxzrrsWB6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d690a699-3bf9-4f87-9dd3-ab8b3761d320"
      },
      "cell_type": "code",
      "source": [
        "fit(model,md,1,opt,F.nll_loss)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea6927f4422440a6a3cc9b3f52cbcb79",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.838118   0.587075  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.58707])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "TZSLX_LCWImx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Testing ur model"
      ]
    },
    {
      "metadata": {
        "id": "ekMt_ORyWDa4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = model(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13-rGf4zWdvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc5c873c-c6f0-4278-ef07-7836ebf75b10"
      },
      "cell_type": "code",
      "source": [
        "get_next('you')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "dbdTQwjAWitI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "674e1bb9-bc39-4cd0-8eb3-aa8516123619"
      },
      "cell_type": "code",
      "source": [
        "get_next('p. ')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "CpjaMsRdWsa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f04b0341-3eb4-4549-eba3-a7b75d687df6"
      },
      "cell_type": "code",
      "source": [
        "get_next('lov')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "v060G3izWwG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4d366f4-c634-4ca2-e20c-0e1eeef58819"
      },
      "cell_type": "code",
      "source": [
        "get_next(' th')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "7wTXZecRXe4m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neurel net(RNN) from scratch\n",
        "**Now we'll create a model that given 8 characters can predict the 9th character**"
      ]
    },
    {
      "metadata": {
        "id": "5WPbB5CxWyvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=8\n",
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]\n",
        "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38yc2NExYOJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat, axis=0)\n",
        "y = np.stack(c_out_dat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c115zawEZf0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating and training the RNN model**"
      ]
    },
    {
      "metadata": {
        "id": "TwEjlE9SYXCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(idx)-cs-1)\n",
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "US_esY8gZrbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class rnnmodel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = torch.cat((h, self.e(c)), 1)\n",
        "            inp = F.relu(self.l_in(inp))\n",
        "            h = F.tanh(self.l_hidden(inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ljCZg3sAa--9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=rnnmodel(vocab_size,n_fac).cuda()\n",
        "opt=optim.Adam(model.parameters(),1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2q1I-_AKbZBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = model(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3CSQTI6qbfhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c4f72d2b-1f9b-4070-961b-3dd34e7883bd"
      },
      "cell_type": "code",
      "source": [
        "fit(model, md, 1, opt, F.nll_loss)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e9c24de0f784250814a369820671760",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.831867   1.801626  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.80163])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "-BiF1YJVcg_7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt,1e-4)#learning rate annealing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZngYpyQcude",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "35a17806-7bfb-44de-bbf8-b3dd6e7791da"
      },
      "cell_type": "code",
      "source": [
        "fit(model, md, 3, opt, F.nll_loss)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33342d8d581b4a149a809cd8373649b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.691983   1.691339  \n",
            " 23%|██▎       | 212/939 [00:06<00:23, 30.78it/s, loss=1.69]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "    1      1.649533   1.666025  \n",
            "    2      1.639801   1.642694  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.64269])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "jnV5E6ecd21R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ]
    },
    {
      "metadata": {
        "id": "Ochs7Xrwc0GR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaa43428-2c94-4293-c809-0e062f1e7d31"
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "HuqBVsEYd1BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd06f340-98a0-4f9a-a7d7-e87494192586"
      },
      "cell_type": "code",
      "source": [
        "get_next('I love y')\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'o'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "2rgHYnKzeIvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a0e9d37-55c4-4a3f-ffe1-0bd9365d17cd"
      },
      "cell_type": "code",
      "source": [
        "get_next(\"sleepin\")\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'g'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "glQbflodfqb2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2uWItXhe6w9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Those outputs look pretty good\n",
        "##End."
      ]
    },
    {
      "metadata": {
        "id": "hnpqKKsYgN_0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}